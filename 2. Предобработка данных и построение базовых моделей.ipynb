{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "2. Предобработка данных и построение базовых моделей.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGONlCskZJ93",
        "colab_type": "text"
      },
      "source": [
        "# **Выявление побочных действий лекарств в микроблогах**\n",
        "\n",
        "Выполнила Ирина Долгалева\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzMyMIhko9CV",
        "colab_type": "text"
      },
      "source": [
        "# 2. Предобработка данных и построение базовых моделей"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZHlVBMSpWgJ",
        "colab_type": "text"
      },
      "source": [
        "Установим то, по дефолту не установлено в колабе:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJjbWtyYziwP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install pymorphy2\n",
        "!pip install spacy\n",
        "!pip install emoji\n",
        "!pip install pattern3\n",
        "!python3 -m spacy download en\n",
        "!python3 -m spacy download fr\n",
        "!pip install pattern3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1T0jEenRqHoD",
        "colab_type": "text"
      },
      "source": [
        "Заимпортируем все бибилиотеки для исследования данных:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEupPQIdZJ97",
        "colab_type": "code",
        "outputId": "d9c2329c-f8da-4f32-fc57-e5b918be02c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, roc_curve\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import WhitespaceTokenizer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from string import punctuation\n",
        "import spacy\n",
        "import emoji\n",
        "from collections import Counter\n",
        "from tqdm import tqdm_notebook\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJJXs3LsZJ-R",
        "colab_type": "text"
      },
      "source": [
        "## Предобработка текстов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UFLd1lpCauB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "exclude = list(punctuation) + list('0123456789—«»₽•')\n",
        "\n",
        "def del_urls(text):\n",
        "    text = re.sub(\"(?:\\@|https?\\://)\\S+\", \"\", text)\n",
        "    text = text.replace('\\u200d️', '')\n",
        "    buf = ''.join(ch for ch in text if ch not in exclude)\n",
        "    return buf\n",
        "\n",
        "def preprocess_russian(text):\n",
        "    buf = del_urls(text)\n",
        "    buf = ''.join(ch for ch in buf if ch not in emoji.UNICODE_EMOJI)\n",
        "    tokens = WhitespaceTokenizer().tokenize(buf.lower())\n",
        "    morph = MorphAnalyzer()\n",
        "    lemmas = []\n",
        "    for t in tokens:\n",
        "        \n",
        "        if not t in stopwords.words('russian') and len(t) > 2:\n",
        "            \n",
        "            try:\n",
        "                lemma = morph.parse(t)[0].normal_form\n",
        "            except:\n",
        "                lemma = t\n",
        "            lemmas.append(lemma)\n",
        "    return lemmas\n",
        "\n",
        "def preprocess_english(text, language):\n",
        "    buf = del_urls(text)\n",
        "    buf = ''.join(ch for ch in buf if ch not in emoji.UNICODE_EMOJI)\n",
        "    tokens = WhitespaceTokenizer().tokenize(buf.lower())\n",
        "    lemmas = []\n",
        "\n",
        "    if language == 'english':\n",
        "        morph = WordNetLemmatizer()\n",
        "\n",
        "    lemmas = []\n",
        "    for t in tokens:\n",
        "        if not t in stopwords.words(language) and len(t) > 2:\n",
        "            lemma = morph.lemmatize(t)\n",
        "            lemmas.append(lemma)\n",
        "            print(t, lemma)\n",
        "    return lemmas"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoBgPh24qR7L",
        "colab_type": "text"
      },
      "source": [
        "Считаем исходные данные:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87LHw51TDxmk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# path = ''\n",
        "\n",
        "# df_en_tr = pd.read_csv(path + 'task2_en_training.tsv', sep=\"\\t\")\n",
        "# df_en_val = pd.read_csv(path + 'task2_en_validation.tsv', sep=\"\\t\")\n",
        "# print(df_en_tr.shape)\n",
        "# print(df_en_val.shape)\n",
        "\n",
        "# df_fr_tr = pd.read_csv(path + 'task2_fr_training.tsv', sep=\"\\t\")\n",
        "# df_fr_val = pd.read_csv(path + 'task2_fr_validation.tsv', sep=\"\\t\")\n",
        "# print(df_fr_tr.shape)\n",
        "# print(df_fr_val.shape)\n",
        "\n",
        "# df_ru_tr = pd.read_csv(path + 'task2_ru_training.tsv', sep=\"\\t\")\n",
        "# df_ru_val = pd.read_csv(path + 'task2_ru_validation.tsv', sep=\"\\t\")\n",
        "# print(df_ru_tr.shape)\n",
        "# print(df_ru_val.shape)\n",
        "\n",
        "# df_en_tr.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgjNBdrjqXy6",
        "colab_type": "text"
      },
      "source": [
        "Предобработаем тексты и сохраним результат:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lk9UIZpWQ9LR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# df_ru_tr['tweet_pr'] = df_ru_tr['tweet'].apply(lambda x: ' '.join(preprocess_russian(x)).strip())\n",
        "# df_ru_val['tweet_pr'] = df_ru_val['tweet'].apply(lambda x: ' '.join(preprocess_russian(x)).strip())\n",
        "# df_ru_tr.to_csv('df_ru_tr.csv', encoding='utf-8-sig')\n",
        "# df_ru_val.to_csv('df_ru_val.csv', encoding='utf-8-sig')\n",
        "# print('Russian texts are preproccessed!')\n",
        "\n",
        "# df_en_val['tweet_pr'] = df_en_val['tweet'].apply(lambda x: ' '.join(preprocess_english(x, 'english')).strip())\n",
        "# df_en_val.to_csv('df_en_val.csv', encoding='utf-8-sig')\n",
        "# df_en_tr['tweet_pr'] = df_en_tr['tweet'].apply(lambda x: ' '.join(preprocess_english(x, 'english')).strip())\n",
        "# df_en_tr.to_csv('df_en_tr.csv', encoding='utf-8-sig')\n",
        "# print('English texts are preproccessed!')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWKX0tTbZJ_f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_ru_tr = pd.read_csv('df_ru_tr.csv', encoding='utf-8-sig')\n",
        "df_ru_val = pd.read_csv('df_ru_val.csv', encoding='utf-8-sig')\n",
        "df_ru_tr['language'] = 'Русский'\n",
        "df_ru_val['language'] = 'Русский'\n",
        "\n",
        "df_en_tr = pd.read_csv('df_en_tr.csv', encoding='utf-8-sig')\n",
        "df_en_val = pd.read_csv('df_en_val.csv', encoding='utf-8-sig')\n",
        "df_en_tr['language'] = 'Английский'\n",
        "df_en_val['language'] = 'Английский'\n",
        "\n",
        "df_tr = df_ru_tr.append(df_en_tr)\n",
        "df_val = df_ru_val.append(df_en_val)\n",
        "df_tr = df_tr.sample(frac=1, random_state=123).reset_index(drop=True)\n",
        "df_val = df_val.sample(frac=1, random_state=1234).reset_index(drop=True)\n",
        "\n",
        "X_train, X_test = df_tr[['tweet_pr']], df_val[['tweet_pr']]\n",
        "y_train, y_test = df_tr['class'], df_val['class']\n",
        "\n",
        "mask_ru_tr = df_tr['language'] == 'Русский'\n",
        "mask_en_tr = df_tr['language'] == 'Английский'\n",
        "mask_ru_te = df_val['language'] == 'Русский'\n",
        "mask_en_te = df_val['language'] == 'Английский'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgD7JwS_qxll",
        "colab_type": "text"
      },
      "source": [
        "Представим тексты в виде матрицы \"термин-документ\" и применим tf-idf: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7n8p16fZKAB",
        "colab_type": "code",
        "outputId": "eb09f832-5ad5-42de-bede-9a48009fc90f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "vectorizer = TfidfVectorizer(min_df=3, ngram_range=(1, 1), max_features=2000)\n",
        "\n",
        "X_train_v = vectorizer.fit_transform(X_train['tweet_pr'])\n",
        "X_train_v = X_train_v.toarray()\n",
        "\n",
        "X_test_v = vectorizer.transform(X_test['tweet_pr'])\n",
        "X_test_v = X_test_v.toarray()\n",
        "\n",
        "len(vectorizer.vocabulary_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKH0k0qU1e10",
        "colab_type": "text"
      },
      "source": [
        "## Построение базовых моделей"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KViPhInXGNFb",
        "colab_type": "text"
      },
      "source": [
        "Определение оптимального порога отсечения по вероятности:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hlmnwXOZKAG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_predict_with_opt_threthold(y_tr, pred_tr, y_te, pred_te):\n",
        "    fpr, tpr, thresholds = roc_curve(y_tr, pred_tr)\n",
        "\n",
        "    f1_scores = []\n",
        "    for th in thresholds:\n",
        "        prediction = np.zeros_like(pred_tr)\n",
        "        prediction[pred_tr >= th] = 1\n",
        "        f1_scores.append(f1_score(y_tr, prediction))\n",
        "    \n",
        "    optimal_idx = np.argmax(f1_scores)\n",
        "    optimal_threshold = thresholds[optimal_idx]\n",
        "\n",
        "    prediction_tr = np.zeros_like(pred_tr)\n",
        "    prediction_tr[pred_tr >= optimal_threshold] = 1\n",
        "    prediction_te = np.zeros_like(pred_te)\n",
        "    prediction_te[pred_te >= optimal_threshold] = 1\n",
        "  \n",
        "    print('Optimal threshold is', optimal_threshold)\n",
        "    print('F1_train =', np.max(f1_scores))\n",
        "    print('F1_test =', f1_score(y_te, prediction_te))\n",
        "    print('Gini train =', 2 * roc_auc_score(y_tr, prediction_tr) - 1)\n",
        "    \n",
        "    return prediction_tr, prediction_te\n",
        "\n",
        "def get_scores(y, pred, prediction):\n",
        "    print('Precision =', precision_score(y, prediction))\n",
        "    print('Recall =', recall_score(y, prediction))\n",
        "    print('F1_score =', f1_score(y, prediction))\n",
        "    print('Gini =', 2 * roc_auc_score(y, pred) - 1)\n",
        "\n",
        "def get_f1(y_tr, pred_tr, y_te, pred_te):\n",
        "    print('F1_all train =', f1_score(y_tr, pred_tr), ', F1_all test =', f1_score(y_te, pred_te))\n",
        "    print('F1_ru train =', f1_score(y_tr[mask_ru_tr], pred_tr[mask_ru_tr]), ', F1_ru test =', f1_score(y_te[mask_ru_te], pred_te[mask_ru_te]))\n",
        "    print('F1_en train =', f1_score(y_tr[mask_en_tr], pred_tr[mask_en_tr]), ', F1_en test =', f1_score(y_te[mask_en_te], pred_te[mask_en_te]))\n",
        "\n",
        "    print('\\nMACRO')\n",
        "    print('F1_all train =', f1_score(y_tr, pred_tr, average='macro'), ', F1_all test =', f1_score(y_te, pred_te, average='macro'))\n",
        "    print('F1_ru train =', f1_score(y_tr[mask_ru_tr], pred_tr[mask_ru_tr], average='macro'), ', F1_ru test =', f1_score(y_te[mask_ru_te], pred_te[mask_ru_te], average='macro'))\n",
        "    print('F1_en train =', f1_score(y_tr[mask_en_tr], pred_tr[mask_en_tr], average='macro'), ', F1_en test =', f1_score(y_te[mask_en_te], pred_te[mask_en_te], average='macro'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JxoBMzsGeEP",
        "colab_type": "text"
      },
      "source": [
        "Определение оптимального порога отсечения на кросс-валидации:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdOe2PRFxnwu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_cv_cutoff(y, y_pred, cv=10):\n",
        "    y_splited = np.array_split(y, cv)\n",
        "    y_pred_splited = np.array_split(y_pred, cv)\n",
        "    \n",
        "    for i in range(cv):\n",
        "        y_tr = np.array([])\n",
        "        y_pred_tr = np.array([])\n",
        "        opt_th = []\n",
        "        for j in range(cv):\n",
        "            if j != i:\n",
        "                y_tr = np.concatenate((y_tr, y_splited[j]))\n",
        "                y_pred_tr = np.concatenate((y_pred_tr, y_pred_splited[j]))\n",
        "\n",
        "        y_te = y_splited[i]\n",
        "        y_pred_te = y_pred_splited[i]\n",
        "\n",
        "        fpr, tpr, thresholds = roc_curve(y_tr, y_pred_tr)\n",
        "\n",
        "        f1_scores = []\n",
        "        pr = []\n",
        "        for th in thresholds:\n",
        "            prediction_tr = np.zeros_like(y_pred_tr)\n",
        "            prediction_tr[y_pred_tr >= th] = 1\n",
        "\n",
        "            prediction_te = np.zeros_like(y_pred_te)\n",
        "            prediction_te[y_pred_te >= th] = 1\n",
        "\n",
        "            f1_scores.append((th, f1_score(y_tr, prediction_tr), f1_score(y_te, prediction_te)))\n",
        "            pr.append((th, precision_score(y_tr, prediction_tr), recall_score(y_tr, prediction_tr), f1_score(y_tr, prediction_tr)))\n",
        "\n",
        "        optimal_idx = np.argmax([x[1] for x in f1_scores])\n",
        "        optimal_threshold = thresholds[optimal_idx]\n",
        "\n",
        "        tr_f1 = [x[1] for x in f1_scores if x[0] == optimal_threshold]\n",
        "        te_f1 = [x[2] for x in f1_scores if x[0] == optimal_threshold]\n",
        "        print(optimal_threshold, tr_f1, te_f1)\n",
        "\n",
        "    return pr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGOCWXfd5gaE",
        "colab_type": "text"
      },
      "source": [
        "### Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-H0mzOkkC4xp",
        "colab_type": "code",
        "outputId": "844a0833-d68a-479d-a67c-7df764c41d83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "nb = GaussianNB()\n",
        "nb.fit(X_train_v, y_train)\n",
        "\n",
        "pred_nb_tr = nb.predict_proba(X_train_v)[:,1]\n",
        "pred_nb_te = nb.predict_proba(X_test_v)[:,1]\n",
        "prediction_nb_tr, prediction_nb_te = get_predict_with_opt_threthold(y_train, pred_nb_tr, y_test, pred_nb_te)\n",
        "\n",
        "get_scores(y_test, pred_nb_te, prediction_nb_te)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Optimal threshold is 1.0\n",
            "F1_train = 0.2302553655185483\n",
            "F1_test = 0.19897144883844656\n",
            "Gini train = 0.32636577464163663\n",
            "Precision = 0.11148648648648649\n",
            "Recall = 0.9242174629324547\n",
            "F1_score = 0.19897144883844656\n",
            "Gini = 0.18510990556800944\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vs--Yr-yJsdB",
        "colab_type": "code",
        "outputId": "9c42d7f0-4a97-41f4-8911-a16cc8c79755",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "get_f1(y_train, prediction_nb_tr, y_test, prediction_nb_te)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1_all train = 0.2302553655185483 , F1_all test = 0.19897144883844656\n",
            "F1_ru train = 0.21398347773524076 , F1_ru test = 0.18666666666666665\n",
            "F1_en train = 0.23525768087215068 , F1_en test = 0.20256645279560037\n",
            "\n",
            "MACRO\n",
            "F1_all train = 0.3625391438456832 , F1_all test = 0.30514192147383035\n",
            "F1_ru train = 0.33672708596475215 , F1_ru test = 0.3002298850574712\n",
            "F1_en train = 0.37015449790881433 , F1_en test = 0.3065677792433287\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hx0xZnpAC-bl",
        "colab_type": "text"
      },
      "source": [
        "Log Reg"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "va4o7iu375e0",
        "colab_type": "code",
        "outputId": "66401239-0148-4ea7-c04b-e99575a84249",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# lr = LogisticRegression(solver='saga',random_state=123, max_iter=1000)\n",
        "# parameters = {\n",
        "#               'penalty': ['l1', 'l2'],\n",
        "#               'C': [0.4, 0.6, 0.8, 0.9]\n",
        "#              }\n",
        "# clf = GridSearchCV(lr, parameters, cv=10, scoring='f1')\n",
        "\n",
        "clf = LogisticRegression(penalty='l2', C=0.8, solver='lbfgs', random_state=1273, max_iter=1000)\n",
        "clf.fit(X_train_v, y_train)\n",
        "\n",
        "pred_lr_tr = clf.predict_proba(X_train_v)[:,1]\n",
        "pred_lr_te = clf.predict_proba(X_test_v)[:,1]\n",
        "prediction_lr_tr, prediction_lr_te = get_predict_with_opt_threthold(y_train, pred_lr_tr, y_test, pred_lr_te)\n",
        "\n",
        "get_scores(y_test, pred_lr_te, prediction_lr_te)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Optimal threshold is 0.2142165759435533\n",
            "F1_train = 0.5544515103338632\n",
            "F1_test = 0.44099797707349964\n",
            "Gini train = 0.5230278975138198\n",
            "Precision = 0.3732876712328767\n",
            "Recall = 0.5387149917627677\n",
            "F1_score = 0.44099797707349964\n",
            "Gini = 0.6925190570255053\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjJ6L7gLGBV0",
        "colab_type": "code",
        "outputId": "514c48cb-865f-40c5-d314-28c67493ecc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "get_f1(y_train, prediction_lr_tr, y_test, prediction_lr_te)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1_all train = 0.5544515103338632 , F1_all test = 0.44099797707349964\n",
            "F1_ru train = 0.4449339207048458 , F1_ru test = 0.35684647302904565\n",
            "F1_en train = 0.5785645004849661 , F1_en test = 0.4573268921095008\n",
            "\n",
            "MACRO\n",
            "F1_all train = 0.7539858513606459 , F1_all test = 0.6854579876068319\n",
            "F1_ru train = 0.7001106793020326 , F1_ru test = 0.6507742889583331\n",
            "F1_en train = 0.7657728897836582 , F1_en test = 0.6913268628506732\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7a6GV-fLeMk",
        "colab_type": "code",
        "outputId": "ec357137-a866-4fc2-c3dd-42cf5252514b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "pr = get_cv_cutoff(y_train, pred_lr_tr, cv=3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.2142165759435533 [0.5618990384615384] [0.5399061032863849]\n",
            "0.21240434888169568 [0.5606326889279437] [0.5410628019323672]\n",
            "0.19547897584363993 [0.541620421753607] [0.5709552733296522]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrV_cIsooxoJ",
        "colab_type": "text"
      },
      "source": [
        "Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j55-xeNTo2p1",
        "colab_type": "code",
        "outputId": "ee55d48a-ae7e-4293-cfe0-4fac63eb2d74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "rf = RandomForestClassifier(random_state=123, n_estimators=100, max_depth=4, \\\n",
        "                            max_samples=0.6, min_samples_leaf=20, min_samples_split=30, \\\n",
        "                            max_features=30)\n",
        "rf.fit(X_train_v, y_train)\n",
        "\n",
        "pred_rf_tr = rf.predict_proba(X_train_v)[:,1]\n",
        "pred_rf_te = rf.predict_proba(X_test_v)[:,1]\n",
        "prediction_rf_tr, prediction_rf_te = get_predict_with_opt_threthold(y_train, pred_rf_tr, y_test, pred_rf_te)\n",
        "\n",
        "get_scores(y_test, pred_rf_te, prediction_rf_te)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Optimal threshold is 0.09896743065585221\n",
            "F1_train = 0.40654123439423245\n",
            "F1_test = 0.3641755634638197\n",
            "Gini train = 0.38797103697451685\n",
            "Precision = 0.2845227062094532\n",
            "Recall = 0.5057660626029654\n",
            "F1_score = 0.3641755634638197\n",
            "Gini = 0.5277607937156821\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gt9ECZvso3e2",
        "colab_type": "code",
        "outputId": "ffe44257-e37e-4642-b19c-83d04dffb4c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "get_f1(y_train, prediction_rf_tr, y_test, prediction_rf_te)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1_all train = 0.40654123439423245 , F1_all test = 0.3641755634638197\n",
            "F1_ru train = 0.2725 , F1_ru test = 0.2403846153846154\n",
            "F1_en train = 0.4284837323511356 , F1_en test = 0.3815967523680649\n",
            "\n",
            "MACRO\n",
            "F1_all train = 0.6678047799931903 , F1_all test = 0.6359842207479084\n",
            "F1_ru train = 0.6106788224956063 , F1_ru test = 0.5923361722903331\n",
            "F1_en train = 0.6756655837524304 , F1_en test = 0.6388074774354545\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jblaoM7PDN-0",
        "colab_type": "text"
      },
      "source": [
        "XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svoJRH85vnBd",
        "colab_type": "code",
        "outputId": "fc971f62-cc72-4a5a-8b4a-341d8c64d372",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# xgb_model = XGBClassifier(random_state=123, n_estimators=10)\n",
        "\n",
        "# parameters = {\n",
        "#               'max_depth': [2, 3]\n",
        "#              }\n",
        "# xgb = GridSearchCV(xgb_model, parameters, cv=10, scoring='f1')\n",
        "\n",
        "xgb = XGBClassifier(random_state=123, n_estimators=100, subsample=0.5, max_depth=2, \\\n",
        "                    colsample_bytree=0.6, colsample_bylevel=0.6, colsample_bynode=0.6)\n",
        "xgb.fit(X_train_v, y_train)\n",
        "\n",
        "pred_xgb_tr = xgb.predict_proba(X_train_v)[:,1]\n",
        "pred_xgb_te = xgb.predict_proba(X_test_v)[:,1]\n",
        "prediction_xgb_tr, prediction_xgb_te = get_predict_with_opt_threthold(y_train, pred_xgb_tr, y_test, pred_xgb_te)\n",
        "\n",
        "get_scores(y_test, pred_xgb_te, prediction_xgb_te)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Optimal threshold is 0.12440963\n",
            "F1_train = 0.41157024793388425\n",
            "F1_test = 0.3647128478389579\n",
            "Gini train = 0.41318309089584004\n",
            "Precision = 0.2846580406654344\n",
            "Recall = 0.5074135090609555\n",
            "F1_score = 0.3647128478389579\n",
            "Gini = 0.5224477856974197\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXF0HoPF1qxp",
        "colab_type": "code",
        "outputId": "844a71b9-9e13-4bf7-9657-3999ec78debe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "get_f1(y_train, prediction_xgb_tr, y_test, prediction_xgb_te)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1_all train = 0.41157024793388425 , F1_all test = 0.3647128478389579\n",
            "F1_ru train = 0.3132803632236095 , F1_ru test = 0.2727272727272727\n",
            "F1_en train = 0.42832269297736514 , F1_en test = 0.38009675190048375\n",
            "\n",
            "MACRO\n",
            "F1_all train = 0.6680876357209343 , F1_all test = 0.6361979450413925\n",
            "F1_ru train = 0.6298679008789966 , F1_ru test = 0.6049574978911167\n",
            "F1_en train = 0.6730271278300339 , F1_en test = 0.6392038005052809\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SU9gPyv0HUr",
        "colab_type": "text"
      },
      "source": [
        "Списко значимых переменных из модели XGBoost:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1t49xr5K0wGY",
        "colab_type": "code",
        "outputId": "850b7fec-85f6-469e-e898-960e9ac4059b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "xgb_imp = xgb.feature_importances_\n",
        "\n",
        "imp_vars = {}\n",
        "mask_imp_vars = []\n",
        "\n",
        "for i, imp in enumerate(xgb_imp):\n",
        "    if imp != 0:# and len(imp_vars) <= 20:\n",
        "        imp_vars[vectorizer.get_feature_names()[i]] = imp\n",
        "        mask_imp_vars.append(True)\n",
        "    else:\n",
        "        mask_imp_vars.append(False)\n",
        "\n",
        "lst = imp_vars.items()\n",
        "for i in sorted(lst, key = lambda x : x[1])[::-1]:\n",
        "    print(i)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('feel', 0.02064121)\n",
            "('withdrawal', 0.020026306)\n",
            "('make', 0.01943361)\n",
            "('hour', 0.018048786)\n",
            "('weight', 0.017561737)\n",
            "('gain', 0.017154697)\n",
            "('cramp', 0.016972065)\n",
            "('dream', 0.016892387)\n",
            "('humira', 0.016664283)\n",
            "('attack', 0.016593108)\n",
            "('изз', 0.01574244)\n",
            "('sleep', 0.015708549)\n",
            "('cause', 0.015692843)\n",
            "('сон', 0.015151574)\n",
            "('headache', 0.014843466)\n",
            "('leg', 0.014770963)\n",
            "('спать', 0.014465898)\n",
            "('sleepy', 0.014211495)\n",
            "('кветиапина', 0.014091654)\n",
            "('asleep', 0.013956622)\n",
            "('allergic', 0.013857023)\n",
            "('часы', 0.013833268)\n",
            "('find', 0.0138045335)\n",
            "('приём', 0.013802541)\n",
            "('stop', 0.013779549)\n",
            "('quetiapine', 0.013777723)\n",
            "('sick', 0.0136053255)\n",
            "('shake', 0.013544537)\n",
            "('побочка', 0.013419584)\n",
            "('wake', 0.013340957)\n",
            "('тошнить', 0.01293862)\n",
            "('day', 0.0129080545)\n",
            "('addict', 0.012804417)\n",
            "('stomach', 0.012656623)\n",
            "('мочь', 0.01264424)\n",
            "('reaction', 0.012473229)\n",
            "('ache', 0.012350848)\n",
            "('tire', 0.012045979)\n",
            "('mouth', 0.011960387)\n",
            "('пить', 0.011918345)\n",
            "('remicade', 0.011820809)\n",
            "('effect', 0.011654647)\n",
            "('день', 0.011421615)\n",
            "('burn', 0.011398381)\n",
            "('pain', 0.011388459)\n",
            "('mess', 0.011174999)\n",
            "('seroquel', 0.0111400215)\n",
            "('viibryd', 0.010916053)\n",
            "('side', 0.010891522)\n",
            "('effexor', 0.010744619)\n",
            "('give', 0.010680422)\n",
            "('work', 0.010599539)\n",
            "('skin', 0.010598028)\n",
            "('овощ', 0.010476373)\n",
            "('banana', 0.010412861)\n",
            "('since', 0.0100592235)\n",
            "('флуоксетина', 0.009933973)\n",
            "('awake', 0.009830762)\n",
            "('metformin', 0.009555022)\n",
            "('велаксина', 0.0095201265)\n",
            "('body', 0.009442684)\n",
            "('аппетит', 0.009229669)\n",
            "('high', 0.009197605)\n",
            "('dry', 0.009183922)\n",
            "('prozac', 0.0091354875)\n",
            "('bad', 0.009122271)\n",
            "('hurt', 0.008279634)\n",
            "('venlafaxine', 0.008153448)\n",
            "('vyvanse', 0.007883492)\n",
            "('weird', 0.0077787754)\n",
            "('generic', 0.007733809)\n",
            "('enbrel', 0.0077238283)\n",
            "('natural', 0.007708736)\n",
            "('commercial', 0.007601189)\n",
            "('olanzapine', 0.007585022)\n",
            "('im', 0.006995775)\n",
            "('такой', 0.0069272155)\n",
            "('heart', 0.0065050256)\n",
            "('lunesta', 0.0064248824)\n",
            "('паксила', 0.004922659)\n",
            "('drug', 0.004287086)\n",
            "('lose', 0.004201213)\n",
            "('пачка', 0.0038067114)\n",
            "('ventolin', 0.0033656221)\n",
            "('lamotrigine', 0.003362431)\n",
            "('trazodone', 0.0032826709)\n",
            "('take', 0.0028543877)\n",
            "('affect', 0.0025521216)\n",
            "('time', 0.0023475)\n",
            "('hate', 0.0020223283)\n",
            "('would', 0.0017424655)\n",
            "('need', 0.0015333929)\n",
            "('crohn', 0.0015148418)\n",
            "('get', 0.0008507339)\n",
            "('have', 0.00043443855)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5. Построение продвинутых моделей: BERT (fine-tuned head and body).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJB2siW7nEtU",
        "colab_type": "text"
      },
      "source": [
        "# **Выявление побочных действий лекарств в микроблогах**\n",
        "\n",
        "Выполнила Ирина Долгалева"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWjalmtJFK5N",
        "colab_type": "text"
      },
      "source": [
        "# 5. Построение продвинутых моделей: BERT (fine-tuned head and body)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FawytbtmnoDy",
        "colab_type": "text"
      },
      "source": [
        "Доустановим библиотеки:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuOpHDT-Aujn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install pytorch_transformers\n",
        "!pip install transformers\n",
        "!pip install emoji\n",
        "!pip install pytorch-pretrained-bert"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4tjQP00nwQx",
        "colab_type": "text"
      },
      "source": [
        "Определим машину GPU:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NmMdkZO8R6q",
        "colab_type": "code",
        "outputId": "e0ba6479-a432-437c-98a9-652de9628afd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import torch\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "torch.cuda.get_device_name(0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tesla P100-PCIE-16GB'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVHgAddEoAF9",
        "colab_type": "text"
      },
      "source": [
        "Заимпортируем бибилотеки:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ok002ceNB8E7",
        "colab_type": "code",
        "outputId": "5adb8d2e-ced5-4d57-96b7-327cf8ee57a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pytorch_pretrained_bert import BertAdam, BertForSequenceClassification\n",
        "from tqdm import tqdm, trange, notebook\n",
        "import pandas as pd\n",
        "import io\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "from tqdm import tqdm_notebook\n",
        "import emoji\n",
        "\n",
        "import torch.nn.functional as F\n",
        "from torch.utils import data\n",
        "import torch.nn as nn\n",
        "from sklearn.metrics import f1_score\n",
        "from transformers import BertTokenizer, BertConfig, BertModel\n",
        "import datetime\n",
        "import os\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, roc_curve\n",
        "import random \n",
        "\n",
        "% matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4sZ_CJcW7iia",
        "colab_type": "text"
      },
      "source": [
        "Считаем и подготовим данные:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYsV4H8fCpZ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_ru_tr = pd.read_csv('df_ru_tr.csv', encoding='utf-8-sig')\n",
        "df_ru_val = pd.read_csv('df_ru_val.csv', encoding='utf-8-sig')\n",
        "df_ru_tr['language'] = 'Русский'\n",
        "df_ru_val['language'] = 'Русский'\n",
        "\n",
        "df_en_tr = pd.read_csv('df_en_tr.csv', encoding='utf-8-sig')\n",
        "df_en_val = pd.read_csv('df_en_val.csv', encoding='utf-8-sig')\n",
        "df_en_tr['language'] = 'Английский'\n",
        "df_en_val['language'] = 'Английский'\n",
        "\n",
        "df_ru_tr['tweet_light_pr'] = df_ru_tr['tweet'].apply(lambda x: re.sub(\"(?:\\@|https?\\://)\\S+\", \"\", x))\n",
        "df_ru_tr['tweet_light_pr'] = df_ru_tr['tweet_light_pr'].apply(lambda x: ''.join(ch for ch in x if ch not in emoji.UNICODE_EMOJI))\n",
        "df_ru_val['tweet_light_pr'] = df_ru_val['tweet'].apply(lambda x: re.sub(\"(?:\\@|https?\\://)\\S+\", \"\", x))\n",
        "df_ru_val['tweet_light_pr'] = df_ru_val['tweet_light_pr'].apply(lambda x: ''.join(ch for ch in x if ch not in emoji.UNICODE_EMOJI))\n",
        "\n",
        "df_en_tr['tweet_light_pr'] = df_en_tr['tweet'].apply(lambda x: re.sub(\"(?:\\@|https?\\://)\\S+\", \"\", x))\n",
        "df_en_tr['tweet_light_pr'] = df_en_tr['tweet_light_pr'].apply(lambda x: ''.join(ch for ch in x if ch not in emoji.UNICODE_EMOJI))\n",
        "df_en_val['tweet_light_pr'] = df_en_val['tweet'].apply(lambda x: re.sub(\"(?:\\@|https?\\://)\\S+\", \"\", x))\n",
        "df_en_val['tweet_light_pr'] = df_en_val['tweet_light_pr'].apply(lambda x: ''.join(ch for ch in x if ch not in emoji.UNICODE_EMOJI))\n",
        "\n",
        "df_tr = df_ru_tr.append(df_en_tr)\n",
        "df_tr = df_tr.sample(frac=1, random_state=123).reset_index(drop=True)\n",
        "\n",
        "df_val = df_ru_val.append(df_en_val)\n",
        "df_val = df_val.sample(frac=1, random_state=123).reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBmAyZXmoQ7G",
        "colab_type": "text"
      },
      "source": [
        "Для удобства создадим свой класс для датасета:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zN42QOXVt7l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Tweet_Dataset(data.Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]    \n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYpIJQ29oYNV",
        "colab_type": "text"
      },
      "source": [
        "Теперь создадим дата лоудеры:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rA7ClPZZXrF0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "train_set = Tweet_Dataset(df_tr['tweet_light_pr'], df_tr['class'])\n",
        "train_sampler = torch.utils.data.sampler.RandomSampler(train_set)\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=BATCH_SIZE, sampler=train_sampler)\n",
        "\n",
        "test_set = Tweet_Dataset(df_val['tweet_light_pr'], df_val['class'])\n",
        "test_sampler = torch.utils.data.sampler.RandomSampler(test_set)\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=BATCH_SIZE, sampler=test_sampler)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBIDxpMS7rHq",
        "colab_type": "text"
      },
      "source": [
        "## Определим нейросеть, у которой обучается голова и часть тела"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUqwN19gR_dS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Dense_BERT_TR(nn.Module):\n",
        "    def __init__(self, out_dim):\n",
        "        super(Dense_BERT_TR, self).__init__()\n",
        "        \n",
        "        self.bert_layer = BertModel.from_pretrained('bert-base-multilingual-cased')\n",
        "\n",
        "        for param in self.bert_layer.parameters():\n",
        "            param.requires_grad = False\n",
        "            \n",
        "        for param in self.bert_layer.encoder.layer[9:].parameters():\n",
        "            param.requires_grad = True\n",
        "\n",
        "        self.dropout = torch.nn.Dropout(p=0.5)\n",
        "        self.lin_layer1 = nn.Linear(in_features=59, out_features=59)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.lin_layer2 = nn.Linear(in_features=59, out_features=out_dim)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        output = self.bert_layer(input_ids, attention_mask)[0]\n",
        "        output = torch.mean(output, 2)\n",
        "        output = self.lin_layer1(output)\n",
        "        output = self.relu(output)\n",
        "        output = self.dropout(output)\n",
        "        output = self.lin_layer1(output)\n",
        "        output = self.relu(output)\n",
        "        output = self.dropout(output)\n",
        "        output = self.lin_layer2(output)\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDDKLae376mX",
        "colab_type": "text"
      },
      "source": [
        "## Подготовим данные к обучению модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxAeEO0abQPM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_batch_to_bert(batch, max_seq_length=50):\n",
        "\n",
        "    def _get_tokens_padding_attention(data):\n",
        "        tokens = tokenizer.tokenize(data)[:max_seq_length-2]\n",
        "        tokens = ['[CLS]'] + tokens + ['[SEP]'] \n",
        "        ids = tokenizer.convert_tokens_to_ids(tokens) \n",
        "        ids_padded = pad_sequences([ids], maxlen=max_seq_length, truncating=\"post\", padding=\"post\")\n",
        "        ids_padded = ids_padded[0]\n",
        "        attention_mask = np.where(ids_padded != 0, 1, 0)\n",
        "        return ids_padded, attention_mask\n",
        "\n",
        "    bert_features = dict(ids=[],\n",
        "                         attention_mask=[],\n",
        "                         label=[])\n",
        "    \n",
        "    for index, (data, label) in enumerate(zip(*batch)):\n",
        "        ids, attention_mask = _get_tokens_padding_attention(data)\n",
        "        \n",
        "        assert len(ids) == max_seq_length\n",
        "        assert len(attention_mask) == max_seq_length\n",
        "\n",
        "        bert_features['ids'].append(ids)\n",
        "        bert_features['attention_mask'].append(attention_mask) \n",
        "        bert_features['label'].append(label) \n",
        "\n",
        "    return bert_features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5ZJ8Mpt3qZ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def binary_accuracy(preds, y):\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds == y).float()\n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc\n",
        "\n",
        "def binary_f1(preds, y):\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    f1 = f1_score(y.cpu().detach().numpy(), rounded_preds.cpu().detach().numpy(), zero_division=0)    \n",
        "    return f1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHinBqIRvjJm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def train_func(model, iterator, optimizer, criterion=None):\n",
        "    epoch_loss = 0\n",
        "    epoch_f1 = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "    for idx, batch in tqdm(enumerate(iterator)):\n",
        "        batch = prepare_batch_to_bert(batch, max_seq_length=59)\n",
        "\n",
        "        input_ids_tensor = torch.tensor(batch['ids'], dtype=torch.long).to(device)\n",
        "        mask_tensor = torch.tensor(batch['attention_mask'], dtype=torch.long).to(device)\n",
        "        labels_tensor = torch.tensor(batch['label'], dtype=torch.float).to(device)\n",
        "\n",
        "        optimizer.zero_grad()        \n",
        "        probas = model(input_ids_tensor, attention_mask=mask_tensor)\n",
        "        probas = torch.flatten(probas)\n",
        "\n",
        "        loss = criterion(probas, labels_tensor)\n",
        "        acc = binary_accuracy(probas, labels_tensor)\n",
        "        f1 = binary_f1(probas, labels_tensor)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc\n",
        "        epoch_f1 += f1\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1 / len(iterator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDyBiZzdMoi0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def eval_func(model, iterator, optimizer, criterion=None):\n",
        "    epoch_loss = 0\n",
        "    epoch_f1 = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "    for idx, batch in tqdm(enumerate(iterator)):\n",
        "        batch = prepare_batch_to_bert(batch, max_seq_length=59)\n",
        "\n",
        "        input_ids_tensor = torch.tensor(batch['ids'], dtype=torch.long).to(device)\n",
        "        mask_tensor = torch.tensor(batch['attention_mask'], dtype=torch.long).to(device)\n",
        "        labels_tensor = torch.tensor(batch['label'], dtype=torch.float).to(device)\n",
        "\n",
        "        probas = model(input_ids_tensor, attention_mask=mask_tensor)\n",
        "        probas = torch.flatten(probas)\n",
        "\n",
        "        loss = criterion(probas, labels_tensor)\n",
        "        acc = binary_accuracy(probas, labels_tensor)\n",
        "        f1 = binary_f1(probas, labels_tensor)\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc\n",
        "        epoch_f1 += f1\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1 / len(iterator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yELJOp4nGTO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_func(model, iterator, optimizer, criterion=None):\n",
        "    model.eval()\n",
        "    y, y_prob, y_pred = [], [], []\n",
        "    for idx, batch in tqdm(enumerate(iterator)):\n",
        "        batch = prepare_batch_to_bert(batch, max_seq_length=59)\n",
        "\n",
        "        input_ids_tensor = torch.tensor(batch['ids'], dtype=torch.long).to(device)\n",
        "        mask_tensor = torch.tensor(batch['attention_mask'], dtype=torch.long).to(device)\n",
        "        labels_tensor = torch.tensor(batch['label'], dtype=torch.float).to(device)\n",
        "        probas = model(input_ids_tensor, attention_mask=mask_tensor)\n",
        "        probas = torch.flatten(probas)\n",
        "        probas = torch.sigmoid(probas)\n",
        "\n",
        "        y.append(labels_tensor.item())\n",
        "        y_prob.append(probas.item())\n",
        "        y_pred.append(torch.round(probas).item())\n",
        "\n",
        "    return y, y_prob, y_pred\n",
        "\n",
        "\n",
        "def get_f1(y_tr, pred_tr, y_te, pred_te):\n",
        "    mask_ru_tr = df_tr['language'] == 'Русский'\n",
        "    mask_en_tr = df_tr['language'] == 'Английский'\n",
        "    mask_ru_te = df_val['language'] == 'Русский'\n",
        "    mask_en_te = df_val['language'] == 'Английский'\n",
        "\n",
        "    print('USUAL')\n",
        "    print('F1_all train =', f1_score(y_tr, pred_tr), ', F1_all test =', f1_score(y_te, pred_te))\n",
        "    print('F1_ru train =', f1_score(y_tr[mask_ru_tr], pred_tr[mask_ru_tr]), ', F1_ru test =', f1_score(y_te[mask_ru_te], pred_te[mask_ru_te]))\n",
        "    print('F1_en train =', f1_score(y_tr[mask_en_tr], pred_tr[mask_en_tr]), ', F1_en test =', f1_score(y_te[mask_en_te], pred_te[mask_en_te]))\n",
        "\n",
        "    print('\\nMACRO')\n",
        "    print('F1_all train =', f1_score(y_tr, pred_tr, average='macro'), ', F1_all test =', f1_score(y_te, pred_te, average='macro'))\n",
        "    print('F1_ru train =', f1_score(y_tr[mask_ru_tr], pred_tr[mask_ru_tr], average='macro'), ', F1_ru test =', f1_score(y_te[mask_ru_te], pred_te[mask_ru_te], average='macro'))\n",
        "    print('F1_en train =', f1_score(y_tr[mask_en_tr], pred_tr[mask_en_tr], average='macro'), ', F1_en test =', f1_score(y_te[mask_en_te], pred_te[mask_en_te], average='macro'))\n",
        "\n",
        "\n",
        "def get_predict_with_opt_threthold(y_tr, pred_tr, y_te, pred_te):\n",
        "    fpr, tpr, thresholds = roc_curve(y_tr, pred_tr)\n",
        "\n",
        "    f1_scores = []\n",
        "    for th in thresholds:\n",
        "        prediction = np.zeros_like(pred_tr)\n",
        "        prediction[pred_tr >= th] = 1\n",
        "        f1_scores.append(f1_score(y_tr, prediction))\n",
        "    \n",
        "    optimal_idx = np.argmax(f1_scores)\n",
        "    optimal_threshold = thresholds[optimal_idx]\n",
        "\n",
        "    prediction_tr = np.zeros_like(pred_tr)\n",
        "    prediction_tr[pred_tr >= optimal_threshold] = 1\n",
        "    prediction_te = np.zeros_like(pred_te)\n",
        "    prediction_te[pred_te >= optimal_threshold] = 1\n",
        "  \n",
        "    print('Optimal threshold is', optimal_threshold)\n",
        "    print('F1_train =', np.max(f1_scores))\n",
        "    print('F1_test =', f1_score(y_te, prediction_te))\n",
        "    print('Gini train =', 2 * roc_auc_score(y_tr, prediction_tr) - 1)\n",
        "    \n",
        "    return prediction_tr, prediction_te\n",
        "\n",
        "def get_scores(y, pred, prediction):\n",
        "    print('Precision =', precision_score(y, prediction))\n",
        "    print('Recall =', recall_score(y, prediction))\n",
        "    print('F1_score =', f1_score(y, prediction))\n",
        "    print('Gini =', 2 * roc_auc_score(y, pred) - 1)\n",
        "\n",
        "\n",
        "def seed_all(seed_value):\n",
        "    random.seed(seed_value) # Python\n",
        "    np.random.seed(seed_value) # cpu vars\n",
        "    torch.manual_seed(seed_value) # cpu  vars\n",
        "    \n",
        "    if torch.cuda.is_available(): \n",
        "        torch.cuda.manual_seed(seed_value)\n",
        "        torch.cuda.manual_seed_all(seed_value) # gpu vars\n",
        "        torch.backends.cudnn.deterministic = True  #needed\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "\n",
        "\n",
        "def varname(var, dir=locals()):\n",
        "    return [key for key, val in dir.items() if id(val) == id(var)][0]\n",
        "\n",
        "\n",
        "def save_model(model):\n",
        "    model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "    name = varname(model) + '_' + str(datetime.datetime.now())[:19] + '.bin'\n",
        "    torch.save(model_to_save.state_dict(), name)\n",
        "    print('Model ' + name + ' is saved!')\n",
        "\n",
        "\n",
        "def load_model(model_class, model_file):\n",
        "    model = model_class(out_dim=1)\n",
        "    model.load_state_dict(torch.load(model_file))\n",
        "    model.to(device)\n",
        "    return model\n",
        "\n",
        "seed_all(1701)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnjzZ1GQ8EwD",
        "colab_type": "text"
      },
      "source": [
        "### Обучение модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rA7s5CllUNGM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_dense = Dense_BERT_TR(out_dim=1)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam([{'params':model_dense.bert_layer.parameters(), 'lr':1e-5},#уменьшим lr для cлоев BERT\n",
        "                        {'params':model_dense.dropout.parameters()},\n",
        "                        {'params':model_dense.lin_layer1.parameters()},\n",
        "                        {'params':model_dense.lin_layer2.parameters()}\n",
        "                       ], lr=0.00005, weight_decay=1e-4)\n",
        "model_dense = model_dense.cuda()\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwgOimWhUNEF",
        "colab_type": "code",
        "outputId": "1bec4c23-aa0c-4aa9-d4fa-02636760f80a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "for epoch in range(5):\n",
        "    train_loss, train_acc, train_f1 = train_func(model_dense, train_loader, optimizer, criterion=criterion)\n",
        "    valid_loss, valid_acc, valid_f1 = eval_func(model_dense, test_loader, optimizer, criterion=criterion)\n",
        "    \n",
        "    print(f'\\nEpoch: {epoch+1:02}, Train Loss: {train_loss:.3f}, Train acc: {train_acc*100:.2f}, Train f1: {train_f1*100:.2f}%\\n    Val. Loss: {valid_loss:.3f}, Val. acc: {valid_acc*100:.2f} Val. f1: {valid_f1*100:.2f}%\\n')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1665it [01:47, 15.48it/s]\n",
            "416it [00:17, 23.85it/s]\n",
            "2it [00:00, 15.59it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 01, Train Loss: 0.443, Train acc: 87.42, Train f1: 1.58%\n",
            "    Val. Loss: 0.305, Val. acc: 90.88 Val. f1: 0.00%\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1665it [01:47, 15.44it/s]\n",
            "416it [00:17, 23.70it/s]\n",
            "2it [00:00, 15.62it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 02, Train Loss: 0.272, Train acc: 90.85, Train f1: 0.00%\n",
            "    Val. Loss: 0.240, Val. acc: 90.88 Val. f1: 0.00%\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1665it [01:47, 15.46it/s]\n",
            "416it [00:17, 23.67it/s]\n",
            "2it [00:00, 15.78it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 03, Train Loss: 0.232, Train acc: 90.86, Train f1: 0.11%\n",
            "    Val. Loss: 0.232, Val. acc: 90.88 Val. f1: 0.00%\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1665it [01:48, 15.38it/s]\n",
            "416it [00:17, 23.68it/s]\n",
            "2it [00:00, 15.44it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 04, Train Loss: 0.219, Train acc: 90.94, Train f1: 1.48%\n",
            "    Val. Loss: 0.215, Val. acc: 90.88 Val. f1: 0.00%\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1665it [01:47, 15.43it/s]\n",
            "416it [00:17, 23.64it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 05, Train Loss: 0.205, Train acc: 91.28, Train f1: 6.86%\n",
            "    Val. Loss: 0.221, Val. acc: 92.13 Val. f1: 28.87%\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhA-kHRNr8L0",
        "colab_type": "text"
      },
      "source": [
        "### Оценка точности модели:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RxvJkf6O4Xu",
        "colab_type": "code",
        "outputId": "239896b7-1c2e-4100-c211-25a4078931ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "pred_train_dataloader = torch.utils.data.DataLoader(train_set, sampler=train_sampler, batch_size=1)\n",
        "pred_test_dataloader = torch.utils.data.DataLoader(test_set, sampler=test_sampler, batch_size=1)\n",
        "\n",
        "y_tr, y_prob_tr, y_pred_tr = predict_func(model_dense, pred_train_dataloader, optimizer, criterion=criterion)\n",
        "y_te, y_prob_te, y_pred_te = predict_func(model_dense, pred_test_dataloader, optimizer, criterion=criterion)\n",
        "\n",
        "prediction_tr, prediction_te = get_predict_with_opt_threthold(y_tr, y_prob_tr, y_te, y_prob_te)\n",
        "get_scores(y_te, y_pred_te, prediction_te)\n",
        "\n",
        "get_f1(pd.DataFrame(y_tr), pd.DataFrame(y_pred_tr), pd.DataFrame(y_te), pd.DataFrame(y_pred_te))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "26634it [05:15, 84.38it/s]\n",
            "6656it [01:18, 84.49it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Optimal threshold is 0.4474070370197296\n",
            "F1_train = 0.6134874759152216\n",
            "F1_test = 0.5020632737276479\n",
            "Gini train = 0.6055098801065266\n",
            "Precision = 0.4309327036599764\n",
            "Recall = 0.6013179571663921\n",
            "F1_score = 0.5020632737276479\n",
            "Gini = 0.3234864204820438\n",
            "USUAL\n",
            "F1_all train = 0.5002689618074233 , F1_all test = 0.4437367303609342\n",
            "F1_ru train = 0.5166475315729048 , F1_ru test = 0.5019305019305019\n",
            "F1_en train = 0.49525816649104326 , F1_en test = 0.4216691068814056\n",
            "\n",
            "MACRO\n",
            "F1_all train = 0.7313857422558812 , F1_all test = 0.7006880903219384\n",
            "F1_ru train = 0.7397102721088504 , F1_ru test = 0.7278054664051072\n",
            "F1_en train = 0.7288403486413011 , F1_en test = 0.6902294412862948\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPWSIB_3r_PL",
        "colab_type": "text"
      },
      "source": [
        "Теперь сохраним лучшую модель:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Q1_uOSRV5N-",
        "colab_type": "code",
        "outputId": "375aa6a6-8280-4ca2-baed-50735d2637fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "save_model(model_dense)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model model_dense_2020-05-24 15:40:49.bin is saved!\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}